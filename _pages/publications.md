---
layout: archive
title: "Publications"
permalink: /publications/
author_profile: true
---




## Conference Papers
* [Deep Learning From Crowdsourced Labels: Coupled
Cross-entropy Minimization, Identifiability, and Regularization](https://openreview.net/forum?id=_qVhsWyWB9)<br>
  **Shahana Ibrahim**, Tri Nguyen, and Xiao Fu<br>
  submitted to  International Conference on Learning Representations (ICLR), 2023 <br>
  
* [Crowdsourcing via Annotator Co-occurrence Imputation and
Provable Symmetric Nonnegative Matrix Factorization](https://proceedings.mlr.press/v139/ibrahim21a.html)<br>
  **Shahana Ibrahim** and Xiao Fu<br>
   Proceedings of the 38th International Conference on Machine Learning (ICML), 2021 <br>
   
* [Fiber-Sampled Stochastic Mirror
Descent For Tensor Decomposition with beta Divergence](https://ieeexplore.ieee.org/document/9413830)<br>
   Wenqiang Pu, **Shahana Ibrahim**, Xiao Fu, and Mingyi Hong<br>
  IEEE International Conference on Acoustics,
Speech and Signal Processing (ICASSP), 2021 <br>

* [Learning Mixed Membership from Adjacency Graph via Systematic
Edge Query: Identifiability and Algorithm](https://ieeexplore.ieee.org/document/9413541)<br>
  **Shahana Ibrahim** and Xiao Fu<br>
  IEEE International Conference on Acoustics,
Speech and Signal Processing (ICASSP), 2021 <br>


## Journal Papers
* [Deep Learning From Crowdsourced Labels: Coupled
Cross-entropy Minimization, Identifiability, and Regularizatio](https://openreview.net/forum?id=_qVhsWyWB9)<br>
  **Shahana Ibrahim**, Tri Nguyen, and Xiao Fu<br>
  submitted to  International Conference on Learning Representations, 2023 <br>
  
## Workshop Papers
* [Deep Learning From Crowdsourced Labels: Coupled
Cross-entropy Minimization, Identifiability, and Regularizatio](https://openreview.net/forum?id=_qVhsWyWB9)<br>
  **Shahana Ibrahim**, Tri Nguyen, and Xiao Fu<br>
  submitted to  International Conference on Learning Representations, 2023 <br>



Also refer to the [Google Scholar](https://scholar.google.com/citations?user=FxN93qsAAAAJ&hl=en) for my full paper list. <br>
